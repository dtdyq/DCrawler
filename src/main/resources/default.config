crawler.urls.seed=http://www.baidu.com,https://douban.com

#urlPool put urls into fetch queue,the limit size of queue
crawler.urls.fetch.queue.size[final]=128

#size of the queue which used between fetch and resolve
crawler.fetch.resolve.queue.size[final]=64
crawler.fetch.connection.timeout=10000
crawler.fetch.connection.timeInterval=0
crawler.fetch.connection.retryTime=1
crawler.fetch.thread.count=2

#size of queue which used between resolve and urls
crawler.resolve.urls.queue.size[final]=512
crawler.resolve.class.visitClass=minic.dtdyq.impl.